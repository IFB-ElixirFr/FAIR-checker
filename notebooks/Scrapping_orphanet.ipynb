{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "parentdir = \"..\"\n",
    "sys.path.insert(0, parentdir)\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import datetime\n",
    "#from os import path\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from metrics.WebResource import WebResource\n",
    "from rdflib import Graph\n",
    "from xml.dom import minidom\n",
    "from rdflib import ConjunctiveGraph, Namespace, URIRef\n",
    "from rdflib.namespace import RDF, RDFS\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "from rdflib import Graph, URIRef\n",
    "from rdflib.namespace import RDFS, SKOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieve a List of Target URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the xml file\n",
    "mydoc = minidom.parse('Sitemap.xml')\n",
    "urls = mydoc.getElementsByTagName('ExpertLink')\n",
    "\n",
    "with open('URLs.txt', 'w') as f:\n",
    "    for u in urls:\n",
    "        f.write(u.firstChild.data)\n",
    "        f.writelines('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydoc = open('URLs.txt', 'r')\n",
    "urls = mydoc.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feed the RDF Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Namespace(\"http://schema.org/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ratelimit decorator\n",
    "from ratelimit import limits, RateLimitException, sleep_and_retry\n",
    "\n",
    "five_by_seconds = 0.8\n",
    "\n",
    "@sleep_and_retry\n",
    "@limits(calls=1, period=five_by_seconds)\n",
    "def ask_orphanet(u):\n",
    "    wr = WebResource(url=u)\n",
    "    return wr.get_rdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "KG_Total = ConjunctiveGraph()\n",
    "\n",
    "for u in tqdm(urls):\n",
    "    KG_Total += ask_orphanet(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Display the total triples contained in the graph, after scrapping all URLs in the XML file\n",
    "print(f\"Loaded {len(KG_Total)} triples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the KG in a turtle file\n",
    "KG_Total.serialize(\"new_orphanet_dump.ttl\", format=\"turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat new_orphanet_dump.ttl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the file's size\n",
    "#!cat scrapped_orphanet_bioschemas.ttl\n",
    "from pathlib import Path\n",
    "file_size =Path(r'new_orphanet_dump.ttl').stat().st_size\n",
    "print(\"The file size is:\", file_size,\"bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Display Bioschemas Properties Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_from_query_results(res):    \n",
    "    return pd.DataFrame(res.bindings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### display used properties\n",
    "property_counts = \"\"\"\n",
    "SELECT ?p (count(?p) as ?count) WHERE {\n",
    "    ?s ?p ?o .\n",
    "} \n",
    "GROUP BY ?p\n",
    "ORDER BY DESC(?count)\n",
    "\"\"\"\n",
    "\n",
    "res = KG_Total.query(property_counts)\n",
    "print(res)\n",
    "print(\"********** Used properties **********\")\n",
    "df = get_dataframe_from_query_results(res)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Display Bioschemas Classes Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### display used classes\n",
    "classes_counts = \"\"\"\n",
    "SELECT ?c (count(?c) as ?count) WHERE {\n",
    "    ?s rdf:type ?c .\n",
    "} \n",
    "GROUP BY ?c\n",
    "ORDER BY DESC(?count)\n",
    "\"\"\"\n",
    "\n",
    "res = KG_Total.query(classes_counts)\n",
    "print()\n",
    "print(\"********** Used classes **********\")\n",
    "df = get_dataframe_from_query_results(res)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res ,columns=['class','count'])\n",
    "\n",
    "df[\"class\"] = df[\"class\"].astype(\"str\")\n",
    "df[\"count\"] = df[\"count\"].astype(\"int\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_sum=94\n",
    "\n",
    "def pourcentage(x):\n",
    "          return x*100/count_sum\n",
    "def get_suffix(x):\n",
    "      return str(x).split(sep=\"/\")[-1]\n",
    "\n",
    "df2 = df.copy()\n",
    "df2[\"%\"] = df2['count'].apply(pourcentage)\n",
    "df2[\"label\"] = df2['class'].apply(get_suffix)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordering for better visualisation\n",
    "cols = df2.columns.tolist()\n",
    "#cols = [cols[0], cols[3], cols[1], cols[2]]\n",
    "cols = [cols[3], cols[1]]\n",
    "df2 = df2[cols]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"********** ********** Scatter Chart ********** **********\")\n",
    "df2.plot(x ='label', y='count', kind = 'scatter', rot=80)\n",
    "plt.show()\n",
    "\n",
    "print(\"********** ********** Bar Chart ********** **********\")\n",
    "df2.plot(x ='label', y='count', kind = 'bar')\n",
    "plt.show()\n",
    "\n",
    "print(\"********** ********** Pie Chart ********** **********\")\n",
    "\n",
    "my_labels=['MedicalCode','PronounceableText','MedicalCondition']\n",
    "df2.plot.pie(title=\"Pie Chart\",y='count',figsize=(4,4),labels=my_labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e202b6cb132b9357ed023fecdbc194f9a7f520726b3b39fdf8a2279e78a83e12"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
