{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "fc_src = \"../..\"\n",
    "sys.path.insert(0, fc_src)\n",
    "\n",
    "import requests\n",
    "from os import path\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from metrics.WebResource import WebResource\n",
    "from metrics.FAIRMetricsFactory import FAIRMetricsFactory\n",
    "from metrics.AbstractFAIRMetrics import AbstractFAIRMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve a Bioschemas RDF dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = \"bioschemas-dump.ttl\"\n",
    "if not path.isfile(dump):\n",
    "    r = requests.get(\"https://github.com/bio-tools/content/raw/master/datasets/bioschemas-dump.ttl\")\n",
    "    assert r.status_code == 200\n",
    "    with open(dump, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "assert path.isfile(dump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the RDF dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import ConjunctiveGraph, Namespace, URIRef\n",
    "from rdflib.namespace import RDF, RDFS\n",
    "\n",
    "schema = Namespace(\"http://schema.org/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KG = ConjunctiveGraph()\n",
    "KG.parse(dump, format=\"turtle\")\n",
    "print(f\"{len(KG)} loaded triples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = {}\n",
    "for s, p, o in KG.triples((None, RDF.type, schema.SoftwareApplication)):\n",
    "    index[str(s)] = None    \n",
    "print(print(f\"{len(index)} software applications\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_dump():\n",
    "    for i in tqdm(index.keys()):\n",
    "        sub_graph = ConjunctiveGraph()\n",
    "        for s, p, o in KG.triples((URIRef(i), None, None)):\n",
    "            sub_graph.add((s, p, o))\n",
    "        index[i]=sub_graph\n",
    "\n",
    "\n",
    "def get_RDF_sparql(bio_tools_Id):\n",
    "    q = f\"CONSTRUCT {{<{bio_tools_Id}> ?p ?o}} WHERE {{<{bio_tools_Id}> rdf:type schema:SoftwareApplication . <{bio_tools_Id}> ?p ?o .}}\"\n",
    "    res = KG.query(q)\n",
    "    print(res.serialize(format=\"turtle\"))\n",
    "\n",
    "def get_RDF(bio_tools_Id):\n",
    "    sub_graph = ConjunctiveGraph()\n",
    "    for s, p, o in KG.triples((URIRef(bio_tools_Id), None, None)):\n",
    "        sub_graph.add((s, p, o))\n",
    "    print(sub_graph.serialize(format=\"turtle\"))    \n",
    "    \n",
    "#get_RDF_sparql(\"https://bio.tools/bwa\")\n",
    "#get_RDF(\"https://bio.tools/bwa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling 10 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#sample_tool = random.choice(index.keys())\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "samples = random.sample(list(index.items()), 10)\n",
    "#samples = random.sample(list(index.items()), len(index.items()))\n",
    "\n",
    "splitedSize = 1000\n",
    "samples_chunks = [samples[x:x+splitedSize] for x in range(0, len(samples), splitedSize)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating 10 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_collection_remote = []\n",
    "metrics_collection_remote.append(FAIRMetricsFactory.get_F2B(None))\n",
    "metrics_collection_remote.append(FAIRMetricsFactory.get_I2(None))\n",
    "metrics_collection_remote.append(FAIRMetricsFactory.get_R13(None))\n",
    "\n",
    "df_columns = ['ID']\n",
    "for m in metrics_collection_remote:\n",
    "    #print(m.get_principle_tag())\n",
    "    df_columns.append(m.get_principle_tag())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_time_df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "def eval_metrics(web_res):\n",
    "    metrics_collection_remote = []\n",
    "    metrics_collection_remote.append(FAIRMetricsFactory.get_F2B(web_res))\n",
    "    metrics_collection_remote.append(FAIRMetricsFactory.get_I2(web_res))\n",
    "    metrics_collection_remote.append(FAIRMetricsFactory.get_R13(web_res))\n",
    "    \n",
    "    row = {\"ID\":web_res.get_url()}\n",
    "    row_time = {\"ID\":web_res.get_url()}\n",
    "    for m in metrics_collection_remote:\n",
    "        ts1 = time.time()\n",
    "        e = m.evaluate()\n",
    "        duration = round((time.time() - ts1), 2)\n",
    "        if e is not None:\n",
    "            row[m.get_principle_tag()] = e.get_score()\n",
    "            row_time[m.get_principle_tag()] = duration\n",
    "    \n",
    "    return row, row_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mass_eval(samples):\n",
    "    evals = []\n",
    "    exec_time = []\n",
    "\n",
    "    for sample in tqdm(samples):\n",
    "        wr = WebResource(url=sample[0], rdf_graph=sample[1])\n",
    "        row, row_time = eval_metrics(wr)\n",
    "        evals.append(row)\n",
    "        exec_time.append(row_time)\n",
    "        \n",
    "    \n",
    "    return evals, exec_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "i = 0\n",
    "for c in tqdm(samples_chunks):\n",
    "    i += 1\n",
    "    df = pd.DataFrame()\n",
    "    df_time = pd.DataFrame()\n",
    "    \n",
    "    evals, exec_time = mass_eval(c)\n",
    "    df = pd.concat([df, pd.DataFrame.from_records(evals)])\n",
    "    df_time = pd.concat([df_time, pd.DataFrame.from_records(exec_time)])\n",
    "    \n",
    "    df.to_csv(\"../results/biotools/FC_results_long_metrics_\"+str(i)+\".csv\")\n",
    "    df_time.to_csv(\"../results/biotools/exec_time_long_metrics_\"+str(i)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "all_files = glob.glob(\"../results/biotools/FC_results_long*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in tqdm(all_files):\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "df = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from upsetplot import generate_counts, from_contents, generate_samples, UpSet, plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 200 \n",
    "\n",
    "F2B = df[((df[\"F2B\"].astype(int) > 0))][\"ID\"]\n",
    "I2 = df[((df[\"I2\"].astype(int) > 0))][\"ID\"]\n",
    "R13 = df[((df[\"R1.3\"].astype(int) > 0))][\"ID\"]\n",
    "\n",
    "df_upset = from_contents({'F2B': F2B, \n",
    "                          'I2': I2, \n",
    "                          'R13': R13})\n",
    "df_upset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upset = UpSet(df_upset, subset_size='count', show_counts=True, sort_categories_by=None, orientation='horizontal')\n",
    "\n",
    "params = {'legend.fontsize': 8}\n",
    "with plt.rc_context(params):\n",
    "    upset.plot()\n",
    "plt.suptitle(\"Bioinformatics softwares from Bio.Tools\")\n",
    "plt.savefig('../results/biotools-F2B-I2-R13.png', format=\"png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df_time.drop('ID', 1, inplace=True)\n",
    "\n",
    "sns.boxplot(data=df_time)\n",
    "plt.savefig('../results/exec_time.png')\n",
    "print(df_time[\"F2B\"].mean())\n",
    "print(df_time[\"I2\"].mean())\n",
    "print(df_time[\"R1.3\"].mean())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e202b6cb132b9357ed023fecdbc194f9a7f520726b3b39fdf8a2279e78a83e12"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
